{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Potential pitfalls of feature selection with high-dimensional data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore how having many features increases the chances of finding signal in noise. Feature selection can actually increase the possibility that you might \"distill\" a \"signal\" and happen across some effective-looking models even when working with data that have been generated at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Loading packages and defining a couple of functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(Boruta)\n",
    "library(ggplot2)\n",
    "library(caret)\n",
    "library(tidyr)\n",
    "call.do <- function(args, what){do.call(what, args)}\n",
    "plot.window <- function(x, y){\n",
    "    options(repr.plot.width = x, repr.plot.height = y, repr.plot.res = 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>These functions from my (RKOpTris) useful-funs and r-class-tools repositories on GitHub. They are to split the dataset into trai, test and holdout sets, and then to write as objects into the global environment</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tth_split <- function(df, var = NULL, test_prop = 0.15, holdout_prop = 0.15, shuffle_train = F){\n",
    "  stopifnot(is.numeric(test_prop), test_prop >= 0.05, holdout_prop <= test_prop, is.numeric(holdout_prop))\n",
    "  if(!is.null(var)){\n",
    "    tth_split <- split(df, df[[var]])\n",
    "  } else {\n",
    "    tth_split <- list(df)\n",
    "  }\n",
    "  train_prop <- 1 - test_prop - holdout_prop\n",
    "  tth_data <- lapply(tth_split, function(df){\n",
    "    df$.TTH <- sample(c(\"train\", \"test\", \"holdout\"), nrow(df), replace = T, prob = c(train_prop, test_prop, holdout_prop))\n",
    "    df\n",
    "  })\n",
    "  tth_data <- do.call(rbind, tth_data)\n",
    "  row.names(tth_data) <- 1:nrow(tth_data)\n",
    "  tth_data <- tth_data %>% split(tth_data$.TTH)\n",
    "  tth_data <- lapply(tth_data, function(df){df$.TTH <- NULL; df})\n",
    "  if(shuffle_train){\n",
    "    tth_data$train[[var]] <- shuffle(tth_data$train[[var]])\n",
    "  }\n",
    "  tth_data\n",
    "}\n",
    "\n",
    "list_to_objects <- function(x, suffix = NULL, envir = parent.env(environment())){\n",
    "  stopifnot(is.list(x) | is.environment(envir))\n",
    "  if(is.null(names(x))){\n",
    "    names(x) <- paste0(\"X\", 1:length(x))\n",
    "  } \n",
    "  list_names <- names(x)\n",
    "  if(!is.null(suffix)){\n",
    "    object_names <- paste0(suffix, \"_\", list_names)\n",
    "  } else {\n",
    "    object_names <- list_names\n",
    "  }\n",
    "  for(i in 1:length(x)){\n",
    "    assign(object_names[i], x[[list_names[i]]], envir = envir)\n",
    "    message(object_names[i], \" created\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate random dataset and separate observations (randomly) into two classes (a and b) which will be used to train a random forest model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>64</li>\n",
       "\t<li>1025</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 64\n",
       "\\item 1025\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 64\n",
       "2. 1025\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   64 1025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nObservation <- 2^6\n",
    "nFeature <- 2^10\n",
    "set.seed(1138)\n",
    "randomData <- lapply(1:nObservation, function(i){runif(nFeature)}) %>% call.do(rbind) %>% data.frame()\n",
    "nGroup <- 2\n",
    "classSize <- nObservation / nGroup\n",
    "randomData <- randomData %>% mutate(group = rep(letters[1:nGroup], each = classSize))\n",
    "dim(randomData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split data into train, test and holdout sets for random forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "holdback created\n",
      "test created\n",
      "train created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>X6</th><th scope=col>X7</th><th scope=col>X8</th><th scope=col>X9</th><th scope=col>X10</th><th scope=col>...</th><th scope=col>X1016</th><th scope=col>X1017</th><th scope=col>X1018</th><th scope=col>X1019</th><th scope=col>X1020</th><th scope=col>X1021</th><th scope=col>X1022</th><th scope=col>X1023</th><th scope=col>X1024</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.2735481  </td><td>0.1658198  </td><td>0.2716583  </td><td>0.59671162 </td><td>0.6689339  </td><td>0.47903286 </td><td>0.53462407 </td><td>0.9021131  </td><td>0.2794055  </td><td>0.81010312 </td><td>...        </td><td>0.59936817 </td><td>0.40161776 </td><td>0.75901258 </td><td>0.01027292 </td><td>0.1420067  </td><td>0.567931393</td><td>0.2251452  </td><td>0.2794025  </td><td>0.001682388</td><td>a          </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.4369064  </td><td>0.2624905  </td><td>0.5173542  </td><td>0.84487795 </td><td>0.7948039  </td><td>0.17687608 </td><td>0.90222333 </td><td>0.3681251  </td><td>0.1220852  </td><td>0.36096901 </td><td>...        </td><td>0.07580692 </td><td>0.08328123 </td><td>0.09615077 </td><td>0.05752478 </td><td>0.8723098  </td><td>0.339875903</td><td>0.2504070  </td><td>0.4939295  </td><td>0.509679762</td><td>a          </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.9805419  </td><td>0.1242287  </td><td>0.5751676  </td><td>0.07271604 </td><td>0.6763298  </td><td>0.30267699 </td><td>0.86821552 </td><td>0.7064075  </td><td>0.6812734  </td><td>0.76650626 </td><td>...        </td><td>0.07258728 </td><td>0.67698065 </td><td>0.57424622 </td><td>0.37587236 </td><td>0.5659434  </td><td>0.642358562</td><td>0.9803297  </td><td>0.1986621  </td><td>0.166158764</td><td>a          </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.1516652  </td><td>0.9135941  </td><td>0.2806793  </td><td>0.98765521 </td><td>0.8341834  </td><td>0.08730391 </td><td>0.09749321 </td><td>0.9924669  </td><td>0.3992429  </td><td>0.23050736 </td><td>...        </td><td>0.26820880 </td><td>0.93047142 </td><td>0.02388089 </td><td>0.89538908 </td><td>0.6274444  </td><td>0.146701076</td><td>0.9860405  </td><td>0.5730885  </td><td>0.136443190</td><td>a          </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.9415527  </td><td>0.5875131  </td><td>0.8116554  </td><td>0.59386725 </td><td>0.2158728  </td><td>0.52846828 </td><td>0.86244734 </td><td>0.4014504  </td><td>0.1643136  </td><td>0.89367783 </td><td>...        </td><td>0.74079801 </td><td>0.86602918 </td><td>0.80806014 </td><td>0.78082153 </td><td>0.2225391  </td><td>0.017228276</td><td>0.6162191  </td><td>0.2606054  </td><td>0.510471286</td><td>a          </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0.2219987  </td><td>0.1485699  </td><td>0.4536769  </td><td>0.47694581 </td><td>0.7954455  </td><td>0.04507450 </td><td>0.76660145 </td><td>0.8217877  </td><td>0.2482733  </td><td>0.04420001 </td><td>...        </td><td>0.17687233 </td><td>0.81537920 </td><td>0.16013135 </td><td>0.33402010 </td><td>0.2477387  </td><td>0.005409186</td><td>0.8383730  </td><td>0.4582069  </td><td>0.905461462</td><td>a          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & X1 & X2 & X3 & X4 & X5 & X6 & X7 & X8 & X9 & X10 & ... & X1016 & X1017 & X1018 & X1019 & X1020 & X1021 & X1022 & X1023 & X1024 & group\\\\\n",
       "\\hline\n",
       "\t1 & 0.2735481   & 0.1658198   & 0.2716583   & 0.59671162  & 0.6689339   & 0.47903286  & 0.53462407  & 0.9021131   & 0.2794055   & 0.81010312  & ...         & 0.59936817  & 0.40161776  & 0.75901258  & 0.01027292  & 0.1420067   & 0.567931393 & 0.2251452   & 0.2794025   & 0.001682388 & a          \\\\\n",
       "\t2 & 0.4369064   & 0.2624905   & 0.5173542   & 0.84487795  & 0.7948039   & 0.17687608  & 0.90222333  & 0.3681251   & 0.1220852   & 0.36096901  & ...         & 0.07580692  & 0.08328123  & 0.09615077  & 0.05752478  & 0.8723098   & 0.339875903 & 0.2504070   & 0.4939295   & 0.509679762 & a          \\\\\n",
       "\t4 & 0.9805419   & 0.1242287   & 0.5751676   & 0.07271604  & 0.6763298   & 0.30267699  & 0.86821552  & 0.7064075   & 0.6812734   & 0.76650626  & ...         & 0.07258728  & 0.67698065  & 0.57424622  & 0.37587236  & 0.5659434   & 0.642358562 & 0.9803297   & 0.1986621   & 0.166158764 & a          \\\\\n",
       "\t6 & 0.1516652   & 0.9135941   & 0.2806793   & 0.98765521  & 0.8341834   & 0.08730391  & 0.09749321  & 0.9924669   & 0.3992429   & 0.23050736  & ...         & 0.26820880  & 0.93047142  & 0.02388089  & 0.89538908  & 0.6274444   & 0.146701076 & 0.9860405   & 0.5730885   & 0.136443190 & a          \\\\\n",
       "\t7 & 0.9415527   & 0.5875131   & 0.8116554   & 0.59386725  & 0.2158728   & 0.52846828  & 0.86244734  & 0.4014504   & 0.1643136   & 0.89367783  & ...         & 0.74079801  & 0.86602918  & 0.80806014  & 0.78082153  & 0.2225391   & 0.017228276 & 0.6162191   & 0.2606054   & 0.510471286 & a          \\\\\n",
       "\t8 & 0.2219987   & 0.1485699   & 0.4536769   & 0.47694581  & 0.7954455   & 0.04507450  & 0.76660145  & 0.8217877   & 0.2482733   & 0.04420001  & ...         & 0.17687233  & 0.81537920  & 0.16013135  & 0.33402010  & 0.2477387   & 0.005409186 & 0.8383730   & 0.4582069   & 0.905461462 & a          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | X1 | X2 | X3 | X4 | X5 | X6 | X7 | X8 | X9 | X10 | ... | X1016 | X1017 | X1018 | X1019 | X1020 | X1021 | X1022 | X1023 | X1024 | group |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0.2735481   | 0.1658198   | 0.2716583   | 0.59671162  | 0.6689339   | 0.47903286  | 0.53462407  | 0.9021131   | 0.2794055   | 0.81010312  | ...         | 0.59936817  | 0.40161776  | 0.75901258  | 0.01027292  | 0.1420067   | 0.567931393 | 0.2251452   | 0.2794025   | 0.001682388 | a           |\n",
       "| 2 | 0.4369064   | 0.2624905   | 0.5173542   | 0.84487795  | 0.7948039   | 0.17687608  | 0.90222333  | 0.3681251   | 0.1220852   | 0.36096901  | ...         | 0.07580692  | 0.08328123  | 0.09615077  | 0.05752478  | 0.8723098   | 0.339875903 | 0.2504070   | 0.4939295   | 0.509679762 | a           |\n",
       "| 4 | 0.9805419   | 0.1242287   | 0.5751676   | 0.07271604  | 0.6763298   | 0.30267699  | 0.86821552  | 0.7064075   | 0.6812734   | 0.76650626  | ...         | 0.07258728  | 0.67698065  | 0.57424622  | 0.37587236  | 0.5659434   | 0.642358562 | 0.9803297   | 0.1986621   | 0.166158764 | a           |\n",
       "| 6 | 0.1516652   | 0.9135941   | 0.2806793   | 0.98765521  | 0.8341834   | 0.08730391  | 0.09749321  | 0.9924669   | 0.3992429   | 0.23050736  | ...         | 0.26820880  | 0.93047142  | 0.02388089  | 0.89538908  | 0.6274444   | 0.146701076 | 0.9860405   | 0.5730885   | 0.136443190 | a           |\n",
       "| 7 | 0.9415527   | 0.5875131   | 0.8116554   | 0.59386725  | 0.2158728   | 0.52846828  | 0.86244734  | 0.4014504   | 0.1643136   | 0.89367783  | ...         | 0.74079801  | 0.86602918  | 0.80806014  | 0.78082153  | 0.2225391   | 0.017228276 | 0.6162191   | 0.2606054   | 0.510471286 | a           |\n",
       "| 8 | 0.2219987   | 0.1485699   | 0.4536769   | 0.47694581  | 0.7954455   | 0.04507450  | 0.76660145  | 0.8217877   | 0.2482733   | 0.04420001  | ...         | 0.17687233  | 0.81537920  | 0.16013135  | 0.33402010  | 0.2477387   | 0.005409186 | 0.8383730   | 0.4582069   | 0.905461462 | a           |\n",
       "\n"
      ],
      "text/plain": [
       "  X1        X2        X3        X4         X5        X6         X7        \n",
       "1 0.2735481 0.1658198 0.2716583 0.59671162 0.6689339 0.47903286 0.53462407\n",
       "2 0.4369064 0.2624905 0.5173542 0.84487795 0.7948039 0.17687608 0.90222333\n",
       "4 0.9805419 0.1242287 0.5751676 0.07271604 0.6763298 0.30267699 0.86821552\n",
       "6 0.1516652 0.9135941 0.2806793 0.98765521 0.8341834 0.08730391 0.09749321\n",
       "7 0.9415527 0.5875131 0.8116554 0.59386725 0.2158728 0.52846828 0.86244734\n",
       "8 0.2219987 0.1485699 0.4536769 0.47694581 0.7954455 0.04507450 0.76660145\n",
       "  X8        X9        X10        ... X1016      X1017      X1018     \n",
       "1 0.9021131 0.2794055 0.81010312 ... 0.59936817 0.40161776 0.75901258\n",
       "2 0.3681251 0.1220852 0.36096901 ... 0.07580692 0.08328123 0.09615077\n",
       "4 0.7064075 0.6812734 0.76650626 ... 0.07258728 0.67698065 0.57424622\n",
       "6 0.9924669 0.3992429 0.23050736 ... 0.26820880 0.93047142 0.02388089\n",
       "7 0.4014504 0.1643136 0.89367783 ... 0.74079801 0.86602918 0.80806014\n",
       "8 0.8217877 0.2482733 0.04420001 ... 0.17687233 0.81537920 0.16013135\n",
       "  X1019      X1020     X1021       X1022     X1023     X1024       group\n",
       "1 0.01027292 0.1420067 0.567931393 0.2251452 0.2794025 0.001682388 a    \n",
       "2 0.05752478 0.8723098 0.339875903 0.2504070 0.4939295 0.509679762 a    \n",
       "4 0.37587236 0.5659434 0.642358562 0.9803297 0.1986621 0.166158764 a    \n",
       "6 0.89538908 0.6274444 0.146701076 0.9860405 0.5730885 0.136443190 a    \n",
       "7 0.78082153 0.2225391 0.017228276 0.6162191 0.2606054 0.510471286 a    \n",
       "8 0.33402010 0.2477387 0.005409186 0.8383730 0.4582069 0.905461462 a    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tth_split(randomData, \"group\") %>% list_to_objects()\n",
    "head(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We'll do some feature selection on the random features we've created in this random dataset. Boruta, our feature selection algorithm can take a while. You can always load the dataset a couple of lines below. It is running 10 times so be patient! Here we're using the default value of 0.01</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomBoruta <- vector(\"list\", 10)\n",
    "# for(i in 1:length(randomBoruta)){\n",
    "#     randomBoruta[[i]] <- Boruta(select(train, -group), as.factor(train$group), maxRuns = 500, doTrace = 0, pValue = 0.01)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveRDS(randomBoruta, \"randomBoruta.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomBoruta <- readRDS(\"randomBoruta.RDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>In the last notebook about chance patterns in data, we explored the possibility that the more features we have increases the possibility of some features containing signal from the noise that might show as significant in a statistical test. We have used the Boruta algorithm and an alpha level of significance of 0.01. We have 1024 features and so we might expect that ~10 might be significant. In this particaulr randomly generated dataset Boruta, after 10 runs, found and average of ~7. The results are plottied in a histogram.</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Potential number of significant features\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "10.24"
      ],
      "text/latex": [
       "10.24"
      ],
      "text/markdown": [
       "10.24"
      ],
      "text/plain": [
       "[1] 10.24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of important features identified by Boruta in each run\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>11</li>\n",
       "\t<li>8</li>\n",
       "\t<li>6</li>\n",
       "\t<li>4</li>\n",
       "\t<li>5</li>\n",
       "\t<li>7</li>\n",
       "\t<li>7</li>\n",
       "\t<li>5</li>\n",
       "\t<li>7</li>\n",
       "\t<li>6</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 11\n",
       "\\item 8\n",
       "\\item 6\n",
       "\\item 4\n",
       "\\item 5\n",
       "\\item 7\n",
       "\\item 7\n",
       "\\item 5\n",
       "\\item 7\n",
       "\\item 6\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 11\n",
       "2. 8\n",
       "3. 6\n",
       "4. 4\n",
       "5. 5\n",
       "6. 7\n",
       "7. 7\n",
       "8. 5\n",
       "9. 7\n",
       "10. 6\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 11  8  6  4  5  7  7  5  7  6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Mean number of important features identified by Boruta for all runs\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "6.6"
      ],
      "text/latex": [
       "6.6"
      ],
      "text/markdown": [
       "6.6"
      ],
      "text/plain": [
       "[1] 6.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Column `value` joining factors with different levels, coercing to character vector\""
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0CAMAAAD8CC+4AAAAElBMVEUAAAAzMzNNTU1ZWVnr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\ngXgAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Potential number of significant features\")\n",
    "(numPotential <- 0.01 * nFeature)\n",
    "\n",
    "print(\"Number of important features identified by Boruta in each run\")\n",
    "(numImportant <- sapply(randomBoruta, function(x){sum(x$finalDecision == \"Confirmed\")}))\n",
    "\n",
    "print(\"Mean number of important features identified by Boruta for all runs\")\n",
    "mean(numImportant)\n",
    "\n",
    "plot.window(5, 5)\n",
    "data.frame(table(numImportant)) %>% \n",
    "    rename(\"value\" = \"numImportant\", \"count\" = \"Freq\") %>%\n",
    "    right_join(data.frame(value = as.factor(0:12)), by = \"value\") %>%\n",
    "    replace(is.na(.), 0) %>%\n",
    "    mutate(value = factor(value, levels = as.character(0:12))) %>%\n",
    "    ggplot(aes(x = value, y = count)) +\n",
    "    geom_col()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now let's see the difference between training a random forest model on all of the data, versus a model trained on the data containing only the (randomly) important features. On all the data accuracy generally was about chance, but Kappa was low. The best result (mtry = 2, splitrule = gini) was accuracy = 0.65, Kappa = 0.29 (which is about the threshold for whether a model is performing well).</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (3 fold) \n",
       "Summary of sample sizes: 30, 32, 30 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  splitrule   Accuracy   Kappa      \n",
       "     2  gini        0.6458333   0.29166667\n",
       "     2  extratrees  0.5238095   0.04761905\n",
       "    45  gini        0.3988095  -0.20238095\n",
       "    45  extratrees  0.5000000   0.00000000\n",
       "  1024  gini        0.4315476  -0.13690476\n",
       "  1024  extratrees  0.4136905  -0.17261905\n",
       "\n",
       "Tuning parameter 'min.node.size' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 2, splitrule = gini\n",
       " and min.node.size = 1."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run classification on complete data\n",
    "rf_mod <- caret::train(group ~ ., train,\n",
    "                       method = \"ranger\",\n",
    "                       trControl = trainControl(method = \"cv\",\n",
    "                                                number = 3,\n",
    "                                                returnData = F))\n",
    "rf_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Here we have the important features in our dataset of random values.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "notch went outside hinges. Try setting notch=FALSE.\n",
      "notch went outside hinges. Try setting notch=FALSE.\n",
      "notch went outside hinges. Try setting notch=FALSE.\n",
      "notch went outside hinges. Try setting notch=FALSE.\n",
      "notch went outside hinges. Try setting notch=FALSE.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAH0CAMAAACZ9vcfAAAAHlBMVEUAAAAAv8QaGhozMzNN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\nBtBhsAsYQIfBLmD/B7PAWNzpbeVXAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs_train <- train[randomBoruta[[1]]$finalDecision == \"Confirmed\"]\n",
    "fs_train <- fs_train %>% mutate(group = train$group)\n",
    "\n",
    "plot.window(10, 5)\n",
    "fs_train %>% \n",
    "    gather(\"pseudoWavenumber\", \"pseudoAbsorbance\", -group) %>%\n",
    "    ggplot(aes(group, pseudoAbsorbance)) +\n",
    "    geom_boxplot(notch = T) +\n",
    "    geom_jitter(width = 0.1, aes(col = group)) +\n",
    "    facet_wrap(~pseudoWavenumber, nrow = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>If we feature select just those \"important\" features and train a random forest model, we get up to accuracy = 0.85 and Kappa = 0.7 (mtry = 2, splitrule = extratrees) which would be considered a very effective model. This is randomly generated data, remember. We kept aside test and holdout sets to further validate the model. Let's see what we get...</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (3 fold) \n",
       "Summary of sample sizes: 30, 31, 31 \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  mtry  splitrule   Accuracy   Kappa    \n",
       "   2    gini        0.7375000  0.4743362\n",
       "   2    extratrees  0.8458333  0.6951552\n",
       "   6    gini        0.7388889  0.4753647\n",
       "   6    extratrees  0.7597222  0.5194236\n",
       "  11    gini        0.7375000  0.4743362\n",
       "  11    extratrees  0.6958333  0.3940276\n",
       "\n",
       "Tuning parameter 'min.node.size' was held constant at a value of 1\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final values used for the model were mtry = 2, splitrule = extratrees\n",
       " and min.node.size = 1."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run classification on Boruta important features\n",
    "fs_mod <- caret::train(group ~ ., fs_train,\n",
    "                       method = \"ranger\",\n",
    "                       trControl = trainControl(method = \"cv\",\n",
    "                                                number = 3,\n",
    "                                                returnData = F))\n",
    "fs_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The test set produced an accuracy of 0.75! Not an amazing model, but one that is achieving much better than chance (0.5 as its a binary classifier)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Test accuracy:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.75"
      ],
      "text/latex": [
       "0.75"
      ],
      "text/markdown": [
       "0.75"
      ],
      "text/plain": [
       "[1] 0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Test accuracy:\")\n",
    "mean(predict(fs_mod, test) == test$group) %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The predicted values of the holdout set were not so good, but still better-than-chance.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Holdout accuracy:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.667"
      ],
      "text/latex": [
       "0.667"
      ],
      "text/markdown": [
       "0.667"
      ],
      "text/plain": [
       "[1] 0.667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Holdout accuracy:\")\n",
    "mean(predict(fs_mod, holdback) == holdback$group) %>% round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have seen how signal can be discovered in a randomly generated dataset and yield good classification metrics. The results are obviously false in that the data were random and this result means nothing, but it demonstrates that \"signals\" can be found and may produce convincing results.\n",
    "\n",
    "A bit of doubt cast on the model comes from the fact that the holdout accuracy was markedly worse than the test accuracy and for it to be unstable like that should cause the investigator to at least scratch their head.\n",
    "    \n",
    "Being that it is possible that chance patterns can occur in noise, and those patterns are more likely to occur in line with the number of features that are in our data, it is particularly important to scrutinise models and investigate the variable importance to see if it makes sense. <b>We need to use our subject knowledge.</b>\n",
    "    \n",
    "In spectra we have many variables (wavenumbers) and therefore a good chance there will be some patterns that feature selection and traditional machine learning algorithms can find. In the next notebook we will look at assessing variable importance in the context of spectra."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
